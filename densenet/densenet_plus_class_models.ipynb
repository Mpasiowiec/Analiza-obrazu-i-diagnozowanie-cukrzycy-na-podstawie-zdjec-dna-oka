{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from skimage.morphology import skeletonize, square, dilation \n",
    "from PVBM.GeometricalAnalysis import GeometricalVBMs\n",
    "from PIL import Image,ImageFilter\n",
    "from glob import glob\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\micha/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\micha\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\micha\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "img_size = (300, 300)\n",
    "batch_size = 50\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.3998, 0.1676, 0.0636], [0.2762, 0.1356, 0.0666])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.3998, 0.1676, 0.0636], [0.2762, 0.1356, 0.0666])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.3998, 0.1676, 0.0636], [0.2762, 0.1356, 0.0666])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_transforms_vessel = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor()        \n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor()        \n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor()        \n",
    "    ])\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121', pretrained=False)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier  = nn.Sequential(nn.Linear(num_ftrs, 500),nn.Linear(500,  2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOREST_vessel\n",
      "Training\n",
      "accuracy:  0.9957173447537473 \n",
      "recall 0.9956896551724138 \n",
      "precision 0.9956896551724138 \n",
      "specificity 0.9957446808510638 \n",
      "f1_score 0.9956896551724138 \n",
      "matthews_cor 0.9914343360234776\n",
      "Test\n",
      "accuracy:  0.8142857142857143 \n",
      "recall 0.8 \n",
      "precision 0.8235294117647058 \n",
      "specificity 0.8285714285714286 \n",
      "f1_score 0.8115942028985507 \n",
      "matthews_cor 0.6288281455225324\n",
      "REGRESTION_vessel\n",
      "Training\n",
      "accuracy:  0.9978586723768736 \n",
      "recall 0.9956896551724138 \n",
      "precision 1.0 \n",
      "specificity 1.0 \n",
      "f1_score 0.9978401727861772 \n",
      "matthews_cor 0.9957261828483867\n",
      "Test\n",
      "accuracy:  0.8571428571428571 \n",
      "recall 0.8285714285714286 \n",
      "precision 0.8787878787878788 \n",
      "specificity 0.8857142857142857 \n",
      "f1_score 0.8529411764705883 \n",
      "matthews_cor 0.7154547587901781\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9957173447537473 \n",
      "recall 0.9956896551724138 \n",
      "precision 0.9956896551724138 \n",
      "specificity 0.9957446808510638 \n",
      "f1_score 0.9956896551724138 \n",
      "matthews_cor 0.9914343360234776\n",
      "Test\n",
      "accuracy:  0.8428571428571429 \n",
      "recall 0.8 \n",
      "precision 0.875 \n",
      "specificity 0.8857142857142857 \n",
      "f1_score 0.8358208955223881 \n",
      "matthews_cor 0.6882472016116853\n",
      "KNN_vessel\n",
      "Training\n",
      "accuracy:  0.9486081370449678 \n",
      "recall 0.9612068965517241 \n",
      "precision 0.9369747899159664 \n",
      "specificity 0.9361702127659575 \n",
      "f1_score 0.948936170212766 \n",
      "matthews_cor 0.8975252823619773\n",
      "Test\n",
      "accuracy:  0.8142857142857143 \n",
      "recall 0.8 \n",
      "precision 0.8235294117647058 \n",
      "specificity 0.8285714285714286 \n",
      "f1_score 0.8115942028985507 \n",
      "matthews_cor 0.6288281455225324\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9464668094218416 \n",
      "recall 0.9568965517241379 \n",
      "precision 0.9367088607594937 \n",
      "specificity 0.9361702127659575 \n",
      "f1_score 0.9466950959488272 \n",
      "matthews_cor 0.8931486784333532\n",
      "Test\n",
      "accuracy:  0.8 \n",
      "recall 0.7428571428571429 \n",
      "precision 0.8387096774193549 \n",
      "specificity 0.8571428571428571 \n",
      "f1_score 0.787878787878788 \n",
      "matthews_cor 0.6039571739702033\n",
      "FOREST\n",
      "Training\n",
      "accuracy:  1.0 \n",
      "recall 1.0 \n",
      "precision 1.0 \n",
      "specificity 1.0 \n",
      "f1_score 1.0 \n",
      "matthews_cor 1.0\n",
      "Test\n",
      "accuracy:  0.8448275862068966 \n",
      "recall 0.896551724137931 \n",
      "precision 0.8125 \n",
      "specificity 0.7931034482758621 \n",
      "f1_score 0.8524590163934426 \n",
      "matthews_cor 0.6933752452815364\n",
      "REGRESTION\n",
      "Training\n",
      "accuracy:  1.0 \n",
      "recall 1.0 \n",
      "precision 1.0 \n",
      "specificity 1.0 \n",
      "f1_score 1.0 \n",
      "matthews_cor 1.0\n",
      "Test\n",
      "accuracy:  0.7931034482758621 \n",
      "recall 0.7241379310344828 \n",
      "precision 0.84 \n",
      "specificity 0.8620689655172413 \n",
      "f1_score 0.7777777777777777 \n",
      "matthews_cor 0.5918640302493726\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9921671018276762 \n",
      "recall 0.9895287958115183 \n",
      "precision 0.9947368421052631 \n",
      "specificity 0.9947916666666666 \n",
      "f1_score 0.9921259842519685 \n",
      "matthews_cor 0.9843473047754719\n",
      "Test\n",
      "accuracy:  0.8448275862068966 \n",
      "recall 0.8275862068965517 \n",
      "precision 0.8571428571428571 \n",
      "specificity 0.8620689655172413 \n",
      "f1_score 0.8421052631578947 \n",
      "matthews_cor 0.6900655593423543\n",
      "KNN\n",
      "Training\n",
      "accuracy:  0.9477806788511749 \n",
      "recall 0.9057591623036649 \n",
      "precision 0.9885714285714285 \n",
      "specificity 0.9895833333333334 \n",
      "f1_score 0.9453551912568307 \n",
      "matthews_cor 0.8986815052342754\n",
      "Test\n",
      "accuracy:  0.896551724137931 \n",
      "recall 0.896551724137931 \n",
      "precision 0.896551724137931 \n",
      "specificity 0.896551724137931 \n",
      "f1_score 0.896551724137931 \n",
      "matthews_cor 0.7931034482758621\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9530026109660574 \n",
      "recall 0.9162303664921466 \n",
      "precision 0.9887005649717514 \n",
      "specificity 0.9895833333333334 \n",
      "f1_score 0.9510869565217391 \n",
      "matthews_cor 0.9084184358841673\n",
      "Test\n",
      "accuracy:  0.8793103448275862 \n",
      "recall 0.896551724137931 \n",
      "precision 0.8666666666666667 \n",
      "specificity 0.8620689655172413 \n",
      "f1_score 0.8813559322033899 \n",
      "matthews_cor 0.7590721152765897\n",
      "FOREST_prep\n",
      "Training\n",
      "accuracy:  0.9947780678851175 \n",
      "recall 0.9895287958115183 \n",
      "precision 1.0 \n",
      "specificity 1.0 \n",
      "f1_score 0.9947368421052631 \n",
      "matthews_cor 0.9896097554185929\n",
      "Test\n",
      "accuracy:  0.8620689655172413 \n",
      "recall 0.7931034482758621 \n",
      "precision 0.92 \n",
      "specificity 0.9310344827586207 \n",
      "f1_score 0.851851851851852 \n",
      "matthews_cor 0.731126155013931\n",
      "REGRESTION_prep\n",
      "Training\n",
      "accuracy:  0.9765013054830287 \n",
      "recall 0.9581151832460733 \n",
      "precision 0.9945652173913043 \n",
      "specificity 0.9947916666666666 \n",
      "f1_score 0.976 \n",
      "matthews_cor 0.9536352527435783\n",
      "Test\n",
      "accuracy:  0.8793103448275862 \n",
      "recall 0.7931034482758621 \n",
      "precision 0.9583333333333334 \n",
      "specificity 0.9655172413793104 \n",
      "f1_score 0.8679245283018867 \n",
      "matthews_cor 0.7701540462154054\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9660574412532638 \n",
      "recall 0.9476439790575916 \n",
      "precision 0.9836956521739131 \n",
      "specificity 0.984375 \n",
      "f1_score 0.9653333333333333 \n",
      "matthews_cor 0.93273141518165\n",
      "Test\n",
      "accuracy:  0.8793103448275862 \n",
      "recall 0.7931034482758621 \n",
      "precision 0.9583333333333334 \n",
      "specificity 0.9655172413793104 \n",
      "f1_score 0.8679245283018867 \n",
      "matthews_cor 0.7701540462154054\n",
      "KNN_prep\n",
      "Training\n",
      "accuracy:  0.9242819843342036 \n",
      "recall 0.8900523560209425 \n",
      "precision 0.9550561797752809 \n",
      "specificity 0.9583333333333334 \n",
      "f1_score 0.9214092140921409 \n",
      "matthews_cor 0.850498790784923\n",
      "Test\n",
      "accuracy:  0.8793103448275862 \n",
      "recall 0.7931034482758621 \n",
      "precision 0.9583333333333334 \n",
      "specificity 0.9655172413793104 \n",
      "f1_score 0.8679245283018867 \n",
      "matthews_cor 0.7701540462154054\n",
      "SELECTED\n",
      "Training\n",
      "accuracy:  0.9321148825065274 \n",
      "recall 0.8952879581151832 \n",
      "precision 0.9661016949152542 \n",
      "specificity 0.96875 \n",
      "f1_score 0.9293478260869565 \n",
      "matthews_cor 0.8665225648571776\n",
      "Test\n",
      "accuracy:  0.8793103448275862 \n",
      "recall 0.7931034482758621 \n",
      "precision 0.9583333333333334 \n",
      "specificity 0.9655172413793104 \n",
      "f1_score 0.8679245283018867 \n",
      "matthews_cor 0.7701540462154054\n"
     ]
    }
   ],
   "source": [
    "for typ in ['_vessel', '', '_prep']:\n",
    "    data_dir = './data/data_m'+typ\n",
    "    if typ == '_vessel': trans = data_transforms_vessel\n",
    "    else: trans = data_transforms\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), trans[x]) for x in ['train', 'val', 'test']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False, num_workers=4) for x in ['train', 'val', 'test']}\n",
    "\n",
    "    model_ft.load_state_dict(torch.load('models/densenet121'+typ+'_e20_s300_b14.pt'))\n",
    "    model_ft.to(device)\n",
    "    model_ft.eval()\n",
    "\n",
    "    x, y = {}, {}\n",
    "    for set in ['train', 'test']:\n",
    "        for i, data in enumerate(dataloaders[set], 0):\n",
    "            samples, labels = data\n",
    "            with torch.no_grad():\n",
    "                samples = samples.to(device)\n",
    "                output = model_ft.features(samples)\n",
    "                output = nn.AdaptiveAvgPool3d(output_size=(1024,1,1))(output).squeeze()\n",
    "                if i == 0: x[set], y[set] = torch.Tensor.numpy(output.cpu()), torch.Tensor.numpy(labels)\n",
    "                else:\n",
    "                    x[set] = np.concatenate((x[set], torch.Tensor.numpy(output.cpu())))\n",
    "                    y[set] = np.concatenate((y[set], torch.Tensor.numpy(labels)))\n",
    "\n",
    "    print('FOREST'+typ)                    \n",
    "    forest = RandomForestClassifier(n_estimators=750, max_depth=6)\n",
    "    forest.fit(x['train'], y['train'])\n",
    "\n",
    "    prediction = forest.predict(x['train'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['train'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['train'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['train'], prediction)\n",
    "\n",
    "    print('Training\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "    \n",
    "    prediction = forest.predict(x['test'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['test'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['test'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['test'], prediction)\n",
    "\n",
    "    print('Test\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    x['train']= sc.fit_transform(x['train'])\n",
    "    x['test'] = sc.transform(x['test'])\n",
    "\n",
    "    print('REGRESTION'+typ)\n",
    "    \n",
    "    reg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "    reg.fit(x['train'], y['train'])\n",
    "    \n",
    "    prediction = reg.predict(x['train'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['train'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['train'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['train'], prediction)\n",
    "\n",
    "    print('Training\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    prediction = reg.predict(x['test'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['test'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['test'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['test'], prediction)\n",
    "\n",
    "    print('Test\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "    \n",
    "    print('SELECTED')\n",
    "    \n",
    "    sfs1 = RFE(reg, n_features_to_select=0.0833)\n",
    "    sfs1 = sfs1.fit(x['train'], y['train'])\n",
    "    \n",
    "    X_train_sele = sfs1.transform(x['train'])\n",
    "    X_test_sele = sfs1.transform(x['test'])\n",
    "    \n",
    "    reg.fit(X_train_sele, y['train'])\n",
    "    \n",
    "    prediction = reg.predict(X_train_sele)\n",
    "    tn, fp, fn, tp = confusion_matrix(y['train'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['train'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['train'], prediction)\n",
    "\n",
    "    print('Training\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    prediction = reg.predict(X_test_sele)\n",
    "    tn, fp, fn, tp = confusion_matrix(y['test'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['test'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['test'], prediction)\n",
    "\n",
    "    print('Test\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    print('KNN'+typ)\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x['train'], y['train'])\n",
    "    \n",
    "    prediction = knn.predict(x['train'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['train'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['train'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['train'], prediction)\n",
    "\n",
    "    print('Training\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    prediction = knn.predict(x['test'])\n",
    "    tn, fp, fn, tp = confusion_matrix(y['test'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['test'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['test'], prediction)\n",
    "\n",
    "    print('Test\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "    \n",
    "\n",
    "    print('SELECTED')\n",
    "\n",
    "    knn.fit(X_train_sele, y['train'])\n",
    "    \n",
    "    prediction = knn.predict(X_train_sele)\n",
    "    tn, fp, fn, tp = confusion_matrix(y['train'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['train'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['train'], prediction)\n",
    "\n",
    "    print('Training\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)\n",
    "\n",
    "    prediction = knn.predict(X_test_sele)\n",
    "    tn, fp, fn, tp = confusion_matrix(y['test'], prediction).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    specificity = tn/(fp+tn)\n",
    "    f1_sc = f1_score(y['test'], prediction)\n",
    "    matthews_cor = matthews_corrcoef(y['test'], prediction)\n",
    "\n",
    "    print('Test\\naccuracy: ', accuracy, '\\nrecall', recall, '\\nprecision', precision, '\\nspecificity', specificity, '\\nf1_score', f1_sc, '\\nmatthews_cor', matthews_cor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
