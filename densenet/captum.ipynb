{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_labels = {'0':'control', '1':'diabetic'}\n",
    "transform = transforms.Compose([\n",
    " transforms.Resize((300, 300)),\n",
    " transforms.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)\n",
    "\n",
    "pathModel = \"models/densenet121_prep_e50_s300_b14.pt\"\n",
    "transform_normalize = transforms.Normalize(\n",
    "     mean=[0.5023, 0.5017, 0.5019],\n",
    "     std=[0.1245, 0.0934, 0.0581]\n",
    " )\n",
    "\n",
    "model = torchvision.models.densenet121(pretrained=False)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier  = nn.Sequential(nn.Linear(num_ftrs, 500),nn.Linear(500,  2))\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(pathModel))\n",
    "model = model.eval()\n",
    "\n",
    "folder = 'heatmap_captum/prep'\n",
    "if os.path.exists(folder):\n",
    "    shutil.rmtree(folder)\n",
    "os.makedirs(folder + '/integrated_gradients')\n",
    "os.makedirs(folder + '/occlusion')\n",
    "\n",
    "list_path = glob.glob('data/data_m_prep/test/retina/*')+glob.glob('data/data_m_prep/test/control/*')\n",
    "\n",
    "for img_path in list_path:\n",
    "    img = Image.open(img_path)\n",
    "    transformed_img = transform(img)\n",
    "    input = transform_normalize(transformed_img).unsqueeze(0).to(device)\n",
    "\n",
    "    output = model(input)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "    pred_label_idx.squeeze_()\n",
    "    predicted_label = idx_to_labels[str(pred_label_idx.item())]\n",
    "    if img_path.split('\\\\')[-1].split('.')[0].split('_')[1]=='c' or img_path.split('\\\\')[-1].split('.')[0].split('_')[-1] in ['h', 'N']:\n",
    "        true_leb = 'control'\n",
    "    else:\n",
    "        true_leb = 'diabetic'\n",
    "    title = 'Real: ' + true_leb + \\\n",
    "            '\\nPredicted: ' + predicted_label + '(' + str(round(prediction_score.squeeze().item(), 4)) + ')'\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=10)\n",
    "\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                     [(0, '#ffffff'),\n",
    "                                                      (0.25, '#000000'),\n",
    "                                                      (1, '#000000')], N=256)\n",
    "\n",
    "    a = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 [\"original_image\", \"heat_map\", \"heat_map\", \"masked_image\"],\n",
    "                                 [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                 show_colorbar=True,\n",
    "                                 cmap = default_cmap,\n",
    "                                 titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                 outlier_perc=1,\n",
    "                                 fig_size=(30,11)\n",
    "                                 )\n",
    "    a[0].suptitle(title, size=30)\n",
    "    a[0].savefig(folder + '/integrated_gradients/' + img_path.split('\\\\')[-1].split('.')[0])\n",
    "    plt.close()\n",
    "    \n",
    "    noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "\n",
    "    occlusion = Occlusion(model)\n",
    "\n",
    "    attributions_occ = occlusion.attribute(input,\n",
    "                                           strides = (3, 8, 8),\n",
    "                                           target=pred_label_idx,\n",
    "                                           sliding_window_shapes=(3,15, 15),\n",
    "                                           baselines=0)\n",
    "\n",
    "    b = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          [\"original_image\", \"blended_heat_map\", \"blended_heat_map\", \"masked_image\"],\n",
    "                                          [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                          show_colorbar=True,\n",
    "                                          titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                          outlier_perc=2,\n",
    "                                          fig_size=(30,11)\n",
    "                                         )\n",
    "    b[0].suptitle(title, size=30)\n",
    "    b[0].savefig(folder + '/occlusion/' + img_path.split('\\\\')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)\n",
    "\n",
    "pathModel = \"models/densenet121_e50_s300_b14.pt\"\n",
    "transform_normalize = transforms.Normalize(\n",
    "     mean=[0.3998, 0.1676, 0.0636],\n",
    "     std=[0.2762, 0.1356, 0.0666]\n",
    " )\n",
    "\n",
    "\n",
    "model = torchvision.models.densenet121(pretrained=False)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier  = nn.Sequential(nn.Linear(num_ftrs, 500),nn.Linear(500,  2))\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(pathModel))\n",
    "model = model.eval()\n",
    "\n",
    "folder = 'heatmap_captum/raw'\n",
    "if os.path.exists(folder):\n",
    "    shutil.rmtree(folder)\n",
    "os.makedirs(folder + '/integrated_gradients')\n",
    "os.makedirs(folder + '/occlusion')\n",
    "\n",
    "list_path = glob.glob('data/data_m/test/retina/*')+glob.glob('data/data_m/test/control/*')\n",
    "\n",
    "for img_path in list_path:\n",
    "    img = Image.open(img_path)\n",
    "    transformed_img = transform(img)\n",
    "    input = transform_normalize(transformed_img).unsqueeze(0).to(device)\n",
    "\n",
    "    output = model(input)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "    pred_label_idx.squeeze_()\n",
    "    predicted_label = idx_to_labels[str(pred_label_idx.item())]\n",
    "    if img_path.split('\\\\')[-1].split('.')[0].split('_')[1]=='c' or img_path.split('\\\\')[-1].split('.')[0].split('_')[-1] in ['h', 'N']:\n",
    "        true_leb = 'control'\n",
    "    else:\n",
    "        true_leb = 'diabetic'\n",
    "    title = 'Real: ' + true_leb + \\\n",
    "            '\\nPredicted: ' + predicted_label + '(' + str(round(prediction_score.squeeze().item(), 4)) + ')'\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=10)\n",
    "\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                     [(0, '#ffffff'),\n",
    "                                                      (0.25, '#000000'),\n",
    "                                                      (1, '#000000')], N=256)\n",
    "\n",
    "    a = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 [\"original_image\", \"heat_map\", \"heat_map\", \"masked_image\"],\n",
    "                                 [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                 show_colorbar=True,\n",
    "                                 cmap = default_cmap,\n",
    "                                 titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                 outlier_perc=1,\n",
    "                                 fig_size=(30,11)\n",
    "                                 )\n",
    "    a[0].suptitle(title, size=30)\n",
    "    a[0].savefig(folder + '/integrated_gradients/' + img_path.split('\\\\')[-1].split('.')[0])\n",
    "    \n",
    "    noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "\n",
    "    occlusion = Occlusion(model)\n",
    "\n",
    "    attributions_occ = occlusion.attribute(input,\n",
    "                                           strides = (3, 8, 8),\n",
    "                                           target=pred_label_idx,\n",
    "                                           sliding_window_shapes=(3,15, 15),\n",
    "                                           baselines=0)\n",
    "\n",
    "    b = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          [\"original_image\", \"blended_heat_map\", \"blended_heat_map\", \"masked_image\"],\n",
    "                                          [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                          show_colorbar=True,\n",
    "                                          titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                          outlier_perc=2,\n",
    "                                          fig_size=(30,11)\n",
    "                                         )\n",
    "    b[0].suptitle(title, size=30)\n",
    "    b[0].savefig(folder + '/occlusion/' + img_path.split('\\\\')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output(wait=True)\n",
    "\n",
    "pathModel = \"models/densenet121_vessel_e50_s300_b14.pt\"\n",
    "\n",
    "model = torchvision.models.densenet121(pretrained=False)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier  = nn.Sequential(nn.Linear(num_ftrs, 500),nn.Linear(500,  2))\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(pathModel))\n",
    "model = model.eval()\n",
    "\n",
    "folder = 'heatmap_captum/vessel'\n",
    "if os.path.exists(folder):\n",
    "    shutil.rmtree(folder)\n",
    "os.makedirs(folder + '/integrated_gradients')\n",
    "os.makedirs(folder + '/occlusion')\n",
    "\n",
    "list_path = glob.glob('data/data_m_vessel/test/retina/*')+glob.glob('data/data_m_vessel/test/control/*')\n",
    "\n",
    "for img_path in list_path:\n",
    "    img = Image.open(img_path)\n",
    "    transformed_img = transform(img)\n",
    "    transformed_img = transformed_img.expand(3,*transformed_img.shape[1:])\n",
    "\n",
    "    input = transformed_img.unsqueeze(0).to(device)\n",
    "\n",
    "    output = model(input)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "    pred_label_idx.squeeze_()\n",
    "    predicted_label = idx_to_labels[str(pred_label_idx.item())]\n",
    "    if img_path.split('\\\\')[-1].split('.')[0].split('_')[1]=='c' or img_path.split('\\\\')[-1].split('.')[0].split('_')[-1] in ['h', 'N']:\n",
    "        true_leb = 'control'\n",
    "    else:\n",
    "        true_leb = 'diabetic'\n",
    "    title = 'Real: ' + true_leb + \\\n",
    "            '\\nPredicted: ' + predicted_label + '(' + str(round(prediction_score.squeeze().item(), 4)) + ')'\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=10)\n",
    "\n",
    "    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                     [(0, '#ffffff'),\n",
    "                                                      (0.25, '#000000'),\n",
    "                                                      (1, '#000000')], N=256)\n",
    "\n",
    "    a = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 [\"original_image\", \"heat_map\", \"heat_map\", \"masked_image\"],\n",
    "                                 [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                 show_colorbar=True,\n",
    "                                 titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                 cmap=default_cmap,\n",
    "                                 outlier_perc=2,\n",
    "                                 fig_size=(30,11)\n",
    "                                 )\n",
    "    a[0].suptitle(title, size=30)\n",
    "    a[0].savefig(folder + '/integrated_gradients/' + img_path.split('\\\\')[-1].split('.')[0])\n",
    "\n",
    "    noise_tunnel = NoiseTunnel(integrated_gradients)\n",
    "\n",
    "    occlusion = Occlusion(model)\n",
    "\n",
    "    attributions_occ = occlusion.attribute(input,\n",
    "                                           strides = (3, 8, 8),\n",
    "                                           target=pred_label_idx,\n",
    "                                           sliding_window_shapes=(3,15, 15),\n",
    "                                           baselines=0)\n",
    "    b = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          [\"original_image\", \"blended_heat_map\", \"blended_heat_map\", \"masked_image\"],\n",
    "                                          [\"all\", \"positive\", \"negative\", \"positive\" if pred_label_idx.item() == 0 else 'negative'],\n",
    "                                          show_colorbar=True,\n",
    "                                          titles=['orginal', 'positive attribution', 'negative attribution', 'masked'],\n",
    "                                          outlier_perc=2,\n",
    "                                          fig_size=(30,11)\n",
    "                                         )\n",
    "    b[0].suptitle(title, size=30)\n",
    "    b[0].savefig(folder + '/occlusion/' + img_path.split('\\\\')[-1].split('.')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
